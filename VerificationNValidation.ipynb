{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VerificationNValidation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":274},"id":"f2ROoefaP39n","executionInfo":{"status":"ok","timestamp":1639138542868,"user_tz":-330,"elapsed":34523,"user":{"displayName":"SOURABH VASANT GOTHE","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01487965204084447055"}},"outputId":"322ede31-cf0e-41ea-9cb6-ad365a88026b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n"]},{"output_type":"execute_result","data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://051c7bdc2a29:4050\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.0.3</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Colab</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f5d0c435090>"]},"metadata":{},"execution_count":14}],"source":["#######################################\n","###!@0 START INIT ENVIRONMENT\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","#!wget -q https://mirrors.estointernet.in/apache/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz -P /content/drive/MyDrive # link wrong in blog\n","!tar xf /content/drive/Shareddrives/DA231-2021-Aug-Public/spark-3.0.3-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.3-bin-hadoop2.7\"\n","#######################################\n","###!@1 START OF PYSPARK INIT\n","# Provides findspark.init() to make pyspark importable as a regular library.\n","# Resource : https://pypi.org/project/findspark/\n","import findspark\n","findspark.init()\n","findspark.find()\n","from pyspark.sql import SparkSession\n","!pip install import-ipynb\n","import import_ipynb\n","import pandas as pd\n","import pyspark.sql.functions as F\n","from pyspark.sql.functions import col\n","from functools import reduce  \n","from pyspark.sql import DataFrame\n","\n","spark = SparkSession.builder\\\n","         .master(\"local\")\\\n","         .appName(\"Colab\")\\\n","         .config('spark.ui.port', '4050')\\\n","         .getOrCreate()\n","spark\n","# Spark is ready to go within Colab!\n","###!@1 END OF PYSPARK INIT\n","###!@0 END INIT ENVIRONMENT"]},{"cell_type":"code","source":["#Import all the code required\n","%cd /content/drive/Shareddrives/DataEngineeringProject/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lfdpyAISQx_Z","executionInfo":{"status":"ok","timestamp":1639138547269,"user_tz":-330,"elapsed":353,"user":{"displayName":"SOURABH VASANT GOTHE","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01487965204084447055"}},"outputId":"80aaa8b8-e922-481a-bbbe-a43e5a4ecbff"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/DataEngineeringProject\n"]}]},{"cell_type":"code","source":["%reload_ext autoreload\n","%autoreload 2\n","from sourabh import *\n","from Shilpa import *\n","from Syama import *"],"metadata":{"id":"ne2d7RmBRP0A","executionInfo":{"status":"ok","timestamp":1639138549158,"user_tz":-330,"elapsed":667,"user":{"displayName":"SOURABH VASANT GOTHE","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01487965204084447055"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["States = [\"A\", \"B\", \"C\"]\n","\n","basePath = \"/content/drive/Shareddrives/DataEngineeringProject/SouthDistricts/\"\n","\"\"\"\n","  Method to read the data for a particular state on particular time period (current default : 2019_2020)\n","  Drops all the unnecessary columns and replaces nulls with 0 and returns the data\n","\"\"\"\n","def readAllDataForState(state, year=\"2019_2020\"):\n","  path = basePath + year + \"/\" + state + \"/*.csv\"\n","  data = spark.read.option(\"header\",True).option(\"inferSchema\",True).csv(path)\n","  colsNotRequired = (\"Building\", \"Boundary_Wall\", \"Single_Class_Room\",\\\n","                     \"Separate_Room_for_Headmaster\", \"Land_Available\", \"Electricity\",\\\n","                      \"Furniture\", \"Librarian\", \"Boy_Toilet\", \"Girl_Toilet\", \"Drinking_Water\")\n","  data.drop(*colsNotRequired)\n","  data.na.fill(0)\n","  return data"],"metadata":{"id":"_pnhQaWCRSlI","executionInfo":{"status":"ok","timestamp":1639138552049,"user_tz":-330,"elapsed":480,"user":{"displayName":"SOURABH VASANT GOTHE","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01487965204084447055"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["**Q1 Validation**"],"metadata":{"id":"nyyK2OnRau1P"}},{"cell_type":"code","source":["\n","def generateSyntheticDataQ1():\n","  requiredFields = [\"State_Name\", \"District_Name\", \"Location\", \"School_Management_Name\", \"School_Management_Id\", \"Total_Number_of_Schools\", \"Academic_Year\"]\n","\n","  realData = readAllDataForState(\"Karnataka\") #This is just to get the column names/schema/counts, could be any state\n","  schema = realData.schema\n","  pds = realData.toPandas()\n","  syntheticData = spark.createDataFrame(pds, schema=schema)\n","\n","  managementIds = syntheticData.select(\"School_Management_Id\", \"School_Management_Name\").distinct().orderBy(\"School_Management_Id\")\n","  mgtData=[]\n","  for i in managementIds.collect():\n","    mgtData.append(tuple(i))\n","\n","  Academic_Year = 2017\n","  vals = []\n","  ch = 'a'\n","  lenOfmanagement = len(mgtData)\n","  totalNumberOfRowsPerState = 10 * 10 #100\n","  syntheticStates = [\"A\", \"B\", \"C\"]\n","  config = {'A':{'Urban': 0.6, 'Rural': 0.4}, 'B':{'Urban': 0.3, 'Rural': 0.7}, 'C':{'Urban': 0.2, 'Rural': 0.8}}\n","  data = {}\n","  for State in syntheticStates:\n","    vals = []\n","    Location = \"Rural\"\n","    for i in range(0, int(totalNumberOfRowsPerState*config[State]['Rural'])):#40\n","      District_Name = chr(ord(ch) + i%26)\n","      School_Management_Id = mgtData[i % lenOfmanagement][0]\n","      School_Management_Name = mgtData[i % lenOfmanagement][1]\n","      val = (State, District_Name, Location, School_Management_Name, School_Management_Id, 1, Academic_Year)\n","      vals.append(val)\n","\n","    Location = \"Urban\"\n","    for i in range(0, int(totalNumberOfRowsPerState*config[State]['Urban'])):#60\n","        District_Name = chr(ord(ch) + i%26)\n","        School_Management_Id = mgtData[i % lenOfmanagement][0]\n","        School_Management_Name = mgtData[i % lenOfmanagement][1]\n","        val = (State, District_Name, Location, School_Management_Name, School_Management_Id, 1, Academic_Year)\n","        vals.append(val)\n","    Academic_Year +=1\n","    \n","    data[State] = spark.createDataFrame(vals, requiredFields)\n","  return data, config\n"],"metadata":{"id":"jbiDr9GTTke4","executionInfo":{"status":"ok","timestamp":1639138556097,"user_tz":-330,"elapsed":584,"user":{"displayName":"SOURABH VASANT GOTHE","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01487965204084447055"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["data, config = generateSyntheticDataQ1()\n","_, rural_urban_precentages  = state_urban_rural_school_dist(States, data)"],"metadata":{"id":"EVsKG0o4RshS","executionInfo":{"status":"ok","timestamp":1639138571609,"user_tz":-330,"elapsed":14130,"user":{"displayName":"SOURABH VASANT GOTHE","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01487965204084447055"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["successCounter = 0\n","failedCounter = 0\n","for key in config.keys():\n","  total = rural_urban_precentages[key][0][1] + rural_urban_precentages[key][0][2]\n","  \n","  actualVal = config[key]['Rural']\n","  obtainedVal = rural_urban_precentages[key][0][1]/total\n","  #obtainedVal = rural_urban_precentages[key][0][1]\n","  if actualVal == obtainedVal:\n","    successCounter += 1\n","  else:\n","    failedCounter += 1\n","  actualVal = config[key]['Urban']\n","  \n","  obtainedVal = rural_urban_precentages[key][0][2]/total\n","  #obtainedVal = rural_urban_precentages[key][0][2]\n","  if actualVal == obtainedVal:\n","    successCounter += 1\n","  else:\n","    failedCounter += 1\n","\n","if failedCounter == 0:\n","  print(\"Success: All the values are matching\")\n","else:\n","  print(\"Failed: Total \" +str(failedCounter) +\" values aren't matching\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"efgtDW-zpmGQ","executionInfo":{"status":"ok","timestamp":1639138576115,"user_tz":-330,"elapsed":600,"user":{"displayName":"SOURABH VASANT GOTHE","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01487965204084447055"}},"outputId":"ddcb12d3-45c8-493c-81b8-2f87d7981246"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Success: All the values are matching\n"]}]},{"cell_type":"code","source":["q2A, b = districts_highest_rural_schools(States, data)\n","\n","#Followed uniform distribution over districts, so count must be same or diff less than 2\n","successCounter = 0\n","failedCounter = 0\n","for key in config.keys():\n","  vals = b[key]\n","  count = vals[0][1]\n","  for val in vals:\n","    if (val[1] - count) < 2:\n","      successCounter +=1\n","    else:\n","      failedCounter +=1\n","\n","if failedCounter == 0:\n","  print(\"Success: All the values are matching\")\n","else:\n","  print(\"Failed: Total \" +str(failedCounter) +\" values aren't matching\")"],"metadata":{"id":"4YHla88-XRTV","executionInfo":{"status":"ok","timestamp":1639138585003,"user_tz":-330,"elapsed":5557,"user":{"displayName":"SOURABH VASANT GOTHE","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01487965204084447055"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5d4b1a5-88c1-44e6-bcab-3b40202540af"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Success: All the values are matching\n"]}]},{"cell_type":"code","source":["q3A, c = district_urban_rural_category_school_dist(States, data)\n","successCounter = 0\n","failedCounter = 0\n","for key in config.keys():\n","  vals = c[key]\n","  count = 1\n","  for val in vals:\n","    if val[1] == count:\n","      successCounter +=1\n","    else:\n","      failedCounter +=1\n","\n","if failedCounter == 0:\n","  print(\"Success: All the values are matching\")\n","else:\n","  print(\"Failed: Total \" +str(failedCounter) +\" values aren't matching\")"],"metadata":{"id":"E0LbJfjc1bCE","executionInfo":{"status":"ok","timestamp":1639138593283,"user_tz":-330,"elapsed":5659,"user":{"displayName":"SOURABH VASANT GOTHE","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01487965204084447055"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a93ef4f4-a0da-4bb2-ee42-9bfdb87c080f"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Success: All the values are matching\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"wiIGTNPQajmR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Q2 Validation**"],"metadata":{"id":"0VISMapsalvb"}},{"cell_type":"code","source":["def generateSyntheticDataQ2(state, year=\"2019_2020\"):\n","  global\n","  requiredFields = ['State_Name', 'Total_Number_of_Schools', 'Functional_Electricity', 'Playground', 'Library_or_Reading_Corner_or_Book_Bank', 'Newspaper', 'Functional_Boy_Toilet', 'Functional_Girl_Toilet', 'Functional_Toilet_Facility', 'Functional_Urinal_Boy', 'Functional_Urinal_Girl', 'Functional_Urinal', 'Functional_Toilet_and_Urinal', 'Functional_Drinking_Water', 'Water_Purifier', 'Handwash', 'Ramps', 'Internet', 'Computer_Available']\n","  realData = readAllDataForState(state)\n","  schema = realData.schema\n","  #print(schema.names)\n","  pds = realData.toPandas()\n","  syntheticData = spark.createDataFrame(pds, schema=schema)\n","  syntheticStates = [\"A\", \"B\", \"C\"]\n","  syntheticData = syntheticData.select(requiredFields)\n","  syntheticData = syntheticData.filter(syntheticData.State_Name == \"\")\n","  #syntheticData.show()\n","  vals = []\n","  totalNumberOfSchoolsPerState = 10000#00\n","  config = {'A':{'Functional_Electricity': 0.7, 'Playground':0.8, 'Library_or_Reading_Corner_or_Book_Bank':0.45, 'Newspaper':0.30, 'Functional_Boy_Toilet':0.70, 'Functional_Girl_Toilet':0.80, 'Functional_Toilet_Facility':0.85, 'Functional_Urinal_Boy':0.85, 'Functional_Urinal_Girl':0.70, 'Functional_Urinal':0.80, 'Functional_Toilet_and_Urinal':0.85, 'Functional_Drinking_Water':0.40, 'Water_Purifier':0.25, 'Handwash':0.60, 'Ramps':0.11, 'Internet':0.15, 'Computer_Available':0.20},\n","            'B':{'Functional_Electricity': 0.6, 'Playground':0.7, 'Library_or_Reading_Corner_or_Book_Bank':0.35, 'Newspaper':0.20, 'Functional_Boy_Toilet':0.60, 'Functional_Girl_Toilet':0.70, 'Functional_Toilet_Facility':0.75, 'Functional_Urinal_Boy':0.75, 'Functional_Urinal_Girl':0.60, 'Functional_Urinal':0.70, 'Functional_Toilet_and_Urinal':0.75, 'Functional_Drinking_Water':0.30, 'Water_Purifier':0.15, 'Handwash':0.50, 'Ramps':0.09, 'Internet':0.10, 'Computer_Available':0.15}, \n","            'C':{'Functional_Electricity': 0.5, 'Playground':0.6, 'Library_or_Reading_Corner_or_Book_Bank':0.25, 'Newspaper':0.10, 'Functional_Boy_Toilet':0.50, 'Functional_Girl_Toilet':0.60, 'Functional_Toilet_Facility':0.65, 'Functional_Urinal_Boy':0.65, 'Functional_Urinal_Girl':0.50, 'Functional_Urinal':0.60, 'Functional_Toilet_and_Urinal':0.65, 'Functional_Drinking_Water':0.20, 'Water_Purifier':0.05, 'Handwash':0.40, 'Ramps':0.65, 'Internet':0.05, 'Computer_Available':0.10}}\n","\n","  data = []\n","  for State in syntheticStates:\n","    facilitiesAndPercentages = config[State]\n","    facilitiesAndData = {}\n","    for key in facilitiesAndPercentages.keys():\n","      arr = np.zeros(totalNumberOfSchoolsPerState)\n","      endIndex = int(facilitiesAndPercentages[key] * totalNumberOfSchoolsPerState)\n","      arr[:endIndex] = 1\n","      np.random.shuffle(arr)\n","      facilitiesAndData[key] = arr.tolist()\n","\n","    for i in range(0, totalNumberOfSchoolsPerState):\n","      line = []\n","      line.append(State)#State_Name\n","      line.append(1)#Total_Number_of_Schools\n","      for key in requiredFields:\n","        if key == 'State_Name' or key == 'Total_Number_of_Schools':\n","          continue\n","        line.append(facilitiesAndData[key][i])\n","      data.append(tuple(line))\n","\n","  newRow = spark.createDataFrame(data, requiredFields)\n","  syntheticData = syntheticData.union(newRow)\n","  #syntheticData.show(1)\n","  #print(syntheticData.count())\n","\n","  return syntheticData, config"],"metadata":{"id":"_HTT6BbUapBm","executionInfo":{"status":"ok","timestamp":1639138599259,"user_tz":-330,"elapsed":354,"user":{"displayName":"SOURABH VASANT GOTHE","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01487965204084447055"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["data, config = generateSyntheticDataQ2(\"Karnataka\")\n","q2A, b = essentials_schoolper_state(States, data)\n","index = 0\n","successCounter = 0\n","failureCounter = 0\n","for key in config.keys():\n","  counter = 1\n","  for facility in b['names'][1:]:\n","    stateVal = b['values'][index][0]\n","    obtainedVal = b['values'][index][counter]/100\n","    if facility == 'Functional_Newspaper':\n","      facility = 'Newspaper'\n","    actualVal = config[stateVal][facility]\n","    if actualVal == obtainedVal:\n","      successCounter +=1\n","      #print(\"Success, expected --> \" + str(config[stateVal][facility]) + \" Obtained -->\" +  str(obtainedVal))\n","    elif abs(actualVal - obtainedVal) > 0.6:\n","      failureCounter +=1\n","      #print(\"Failed, expected --> \" + str(config[stateVal][facility]) + \" Obtained -->\" +  str(obtainedVal))\n","    counter += 1\n","  index += 1\n","\n","if failureCounter == 0:\n","  print(\"Success: All the values are matching\")\n","else:\n","  print(\"Failed: Total \" +str(failureCounter) +\" values aren't matching\")\n"],"metadata":{"id":"UzQJobQua8t4","executionInfo":{"status":"ok","timestamp":1639138612465,"user_tz":-330,"elapsed":11940,"user":{"displayName":"SOURABH VASANT GOTHE","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01487965204084447055"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9d4092de-b3a7-4a31-b5c3-096c23c6a504"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Success: All the values are matching\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"eW3Gaw_ibFOQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Q3 Validation**"],"metadata":{"id":"Bef8x8zcbwMs"}},{"cell_type":"code","source":["#Q3 Verification\n","def generateSyntheticDataQ3():\n","  \"\"\"\n","  Weightage of featurs:\n","  Functional_Toilet_Facility : [0.25], Functional_Urinal : [0.05], Functional_Drinking_Water : [0.25]\n","  Water_Purifier : [0.25], Water_Tested : [0.05], Handwash : [0.15]\n","  \"\"\"\n","\n","  requiredFields = [\"State_Name\", \"District_Name\", \"Location\", \"Total_Number_of_Schools\", \"Functional_Toilet_Facility\", \"Functional_Urinal\",\\\n","                    \"Functional_Drinking_Water\", \"Water_Purifier\", \"Water_Tested\", \"Handwash\", \"Academic_Year\"]\n","\n","  realData = readAllDataForState(\"Karnataka\") #This is just to get the column names/schema, could be any state\n","  schema = realData.schema\n","  pds = realData.toPandas()\n","  syntheticData = spark.createDataFrame(pds, schema=schema)\n","\n","  vals = []\n","  ch = 'a'\n","\n","  Academic_Year = 2017\n","  totalNumberOfRowsPerState = 10\n","  syntheticStates = [\"A\", \"B\", \"C\"]\n","  config = {'A':[1, 1, 1, 1, 1, 1, 0], 'B':[1, 1, 1, 1, 1, 0, 0], 'C':[1, 1, 1, 1, 0, 1, 0]}\n","  configWeightage = [0, 0.25, 0.05, 0.25, 0.25, 0.05, 0.15]\n","\n","  LocationList = [\"Rural\", \"Urban\"]\n","  data = {}\n","  for State in syntheticStates:\n","    vals = []\n","    for i in range(0, int(totalNumberOfRowsPerState)):\n","      District_Name = chr(ord(ch) + i%26)\n","      Location = LocationList[i % 2]\n","      configValues = config[State]\n","      Total_Number_of_Schools = configValues[0]\n","      Functional_Toilet_Facility = configValues[1]\n","      Functional_Urinal = configValues[2]\n","      Functional_Drinking_Water = configValues[3]\n","      Water_Purifier = configValues[4]\n","      Water_Tested = configValues[5]\n","      Handwash = configValues[6]\n","      val = (State, District_Name, Location, Total_Number_of_Schools, Functional_Toilet_Facility, Functional_Urinal, Functional_Drinking_Water,\\\n","             Water_Purifier, Water_Tested, Handwash,Academic_Year)\n","      vals.append(val)\n","      Academic_Year +=1\n","    \n","    data[State] = spark.createDataFrame(vals, requiredFields)\n","  return data, config, configWeightage"],"metadata":{"id":"vAcwScrSb4PZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data, config, weightage = generateSyntheticDataQ3()\n","ans = buildHygieneScoreGetTop10(States, data)\n","successCounter = 0\n","failedCounter = 0\n","for key in config.keys():\n","  vals = config[key]\n","  percentage = 0\n","  for feature in range(0,len(vals)):\n","    percentage += vals[feature] * weightage[feature]*100\n","\n","  for stateData in ans[4]:\n","    if key == stateData[0]:\n","      if percentage == stateData[1]:\n","        successCounter += 1\n","      else:\n","        failedCounter += 1\n","\n","if failedCounter == 0:\n","  print(\"Success: All the values are matching\")\n","else:\n","  print(\"Failed: Total \" +str(failedCounter) +\" values aren't matching\")"],"metadata":{"id":"o7155Rfmb94T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ASdtsOIab_tA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Q4 Validation**"],"metadata":{"id":"iwPCDx-XcTiW"}},{"cell_type":"code","source":["#Q4 Verification\n","def generateSyntheticDataQ4():\n","\n","  \"\"\"\n","  Weightage of featurs:\n","  Solar_Panel : [0.2], Kitchen_Garden : [0.3], Rain_Water_Harvesting : [0.4]\n","  Incinerator : [0.1]\n","  \"\"\"\n","  requiredFields = [\"State_Name\", \"District_Name\", \"Total_Number_of_Schools\", \"Solar_Panel\", \"Kitchen_Garden\", \"Rain_Water_Harvesting\", \"Incinerator\", \"Academic_Year\"]\n","\n","  realData = readAllDataForState(\"Karnataka\") #This is just to get the column names/schema, could be any state\n","  schema = realData.schema\n","  pds = realData.toPandas()\n","  syntheticData = spark.createDataFrame(pds, schema=schema)\n","\n","  managementIds = syntheticData.select(\"School_Management_Id\", \"School_Management_Name\").distinct().orderBy(\"School_Management_Id\")\n","  mgtData=[]\n","  for i in managementIds.collect():\n","    mgtData.append(tuple(i))\n","\n","  vals = []\n","  ch = 'a'\n","  Academic_Year = 2017\n","  lenOfmanagement = len(mgtData)\n","  totalNumberOfRowsPerState = 1000\n","  syntheticStates = [\"A\", \"B\", \"C\"]\n","  \"State_Name\", \"District_Name\", \"Total_Number_of_Schools\", \"Solar_Panel\", \"Kitchen_Garden\", \"Rain_Water_Harvesting\", \"Incinerator\"\n","  config = {'A':[1, 1, 1, 1, 1], 'B':[1, 1, 0, 1, 1], 'C':[1, 1, 0, 1, 0]}\n","  configWeightage = [0, 0.2, 0.3, 0.4, 0.1]\n","  LocationList = [\"Rural\", \"Urban\"]\n","  data = {}\n","  for State in syntheticStates:\n","    vals = []\n","    for i in range(0, int(totalNumberOfRowsPerState)):\n","      District_Name = chr(ord(ch) + i%26)\n","      configValues = config[State]\n","      Total_Number_of_Schools = configValues[0]\n","      Solar_Panel = configValues[1]\n","      Kitchen_Garden = configValues[2]\n","      Rain_Water_Harvesting = configValues[3]\n","      Incinerator = configValues[4]\n","      val = (State, District_Name, Total_Number_of_Schools, Solar_Panel, Kitchen_Garden, Rain_Water_Harvesting,\\\n","             Incinerator, Academic_Year)\n","      vals.append(val)\n","      Academic_Year +=1\n","    \n","    data[State] = spark.createDataFrame(vals, requiredFields)\n","  return data, config, configWeightage"],"metadata":{"id":"qd_3xsN7cVyQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data, config, weightage = generateSyntheticDataQ4()\n","ans = self_sustain_scoreQ1(States, data)\n","synthValidation = []\n","for i in ans[2].take(10):\n","  synthValidation.append(tuple(i))\n","successCounter = 0\n","failedCounter = 0\n","for key in config.keys():\n","  vals = config[key]\n","  percentage = 0\n","  for feature in range(0,len(vals)):\n","    percentage += vals[feature] * weightage[feature]*100\n","\n","  for stateData in synthValidation:\n","    if key == stateData[0]:\n","      if abs(percentage - stateData[1]) < 0.1:\n","        successCounter += 1\n","      else:\n","        print(\"Failed, expected --> \" + str(percentage) + \" Obtained -->\" +  str(stateData[1]))\n","        failedCounter += 1\n","\n","if failedCounter == 0:\n","  print(\"Success: All the values are matching\")\n","else:\n","  print(\"Failed: Total \" +str(failedCounter) +\" values aren't matching\")"],"metadata":{"id":"h990Cwz-cavv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"aX8I7gJncftS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Q5 Validation**"],"metadata":{"id":"8RaYqSnoclT0"}},{"cell_type":"code","source":["def generateSyntheticDataQ5():\n","  requiredFields = [\"State_Name\", \"Location\", \"Medical_Checkup\", \"Complete_Medical_Checkup\", \"Total_Number_of_Schools\"]\n","\n","  realData = readAllDataForState(\"Karnataka\") #This is just to get the column names/schema, could be any state\n","  schema = realData.schema\n","  pds = realData.toPandas()\n","  syntheticData = spark.createDataFrame(pds, schema=schema)\n","  syntheticData = syntheticData.select(requiredFields)\n","  syntheticData = syntheticData.filter(syntheticData.State_Name == \"\")\n","\n","  southIndiaMedicalCheckupUnavailability = 0.7\n","  totalNumberOfRowsPerState = 2 * 1000\n","  syntheticStates = [\"A\", \"B\", \"C\"]\n","\n","  #Complete Medical Check-up percentage for rural and urban each state\n","  config = {'A':{'Urban': 0.6, 'Rural': 0.4}, 'B':{'Urban': 0.3, 'Rural': 0.7}, 'C':{'Urban': 0.2, 'Rural': 0.8}}\n","  data = {}\n","\n","  for State in syntheticStates:\n","    vals = []\n","    Location = \"Rural\"\n","    ruralPercentage = int(totalNumberOfRowsPerState*config[State]['Rural'])\n","    for i in range(0, ruralPercentage):\n","      if i < (int) (ruralPercentage * (1-southIndiaMedicalCheckupUnavailability)):\n","        val = (State, Location, 1, 1, 1)\n","      else:\n","        val = (State, Location, 0, 1, 1)\n","      vals.append(val)\n","\n","    Location = \"Urban\"\n","    urbanPercentage = int(totalNumberOfRowsPerState*config[State]['Urban'])\n","    for i in range(0, urbanPercentage):\n","      if i < (int) (urbanPercentage * (1-southIndiaMedicalCheckupUnavailability)):\n","        val = (State, Location, 1, 1, 1)\n","      else:\n","        val = (State, Location, 0, 1, 1)\n","      vals.append(val)\n","    data[State] = spark.createDataFrame(vals, requiredFields)\n","    syntheticData = syntheticData.union(data[State])\n","\n","  return syntheticData, southIndiaMedicalCheckupUnavailability"],"metadata":{"id":"grdD6l9ccoX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data, configValue = generateSyntheticDataQ5()\n","q5A, a = getSchoolsLackingMedical(States, data)\n","q5B, b = getUrbanRuralCompleteMedical(States, data)\n","q5C, c = getSchoolsHavingMedical(States, data)\n","successCounter = 0\n","failedCounter = 0\n","for key in a.keys():\n","  if a[key] == configValue*100:\n","    successCounter +=1 \n","  else:\n","    failedCounter +=1\n","if failedCounter == 0:\n","  print(\"Success: All the values are matching\")\n","else:\n","  print(\"Failed: Total \" +str(failedCounter) +\" values aren't matching\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZIGf-jincsbF","executionInfo":{"status":"ok","timestamp":1639105116186,"user_tz":-330,"elapsed":15334,"user":{"displayName":"SYAMA SUDHEESH","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12073134012724765631"}},"outputId":"2c70e60a-8b23-4af3-b4e8-bf58e9f7320a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Success: All the values are matching\n"]}]},{"cell_type":"markdown","source":["**END**"],"metadata":{"id":"R0dCv8yndevM"}}]}